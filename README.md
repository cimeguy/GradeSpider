# 西工大教务处成绩爬虫

   
2019.03完成
<!-- TOC -->

- [西工大教务处成绩爬虫](#西工大教务处成绩爬虫)
    - [功能介绍](#功能介绍)
    - [所需环境](#所需环境)
    - [框架思路](#框架思路)
    - [具体实现、问题与解决](#具体实现问题与解决)
        - [登录](#登录)
        - [爬取](#爬取)
        - [应对反爬虫](#应对反爬虫)
    - [结果图](#结果图)

<!-- /TOC -->

## 功能介绍
1. 模拟登录教务系统      
2. 按用户需求爬取相应成绩
3. 一个简单的应对反爬虫的策略


## 所需环境
- 需要requests、bs4、(lxml)、pandas、(openpyxl)

- 注意，需将所有库都更新到最新，否则部分函数无法使用：
    ``` 
    pip list  # 查看已安装的所有的依赖包
    pip list --outdated -- format==columns  # 像表格一样列出所有已安装的依赖包的当前版本和可升级版本
    # 升级所有依赖包含如下两个命令
    pip install pip-review --user  # 先安装pip-review函数
    pip-review --local --interactive  # 成功升级所有的依赖包
    ```


## 框架思路
1. 首先爬取登录页面的表单中的其他信息，记录下来，输入学号、密码，提交所有表单信息，随机选择User-agent模拟浏览器登录；
2. 添加session，使得能够访问同一个网站的不同页面；
3. 代码本身通用，支持爬取所有学期，不过考虑到2017年入学，之前没有成绩，故只给出从“2017-2018秋”至今所有学期的选项，可以查看单个学期，也可以查看所有学期。输入选项，按需求爬取，保存至`output/***.xlsx`


## 具体实现、问题与解决
### 登录
- 问题
  
    一开始决定从翱翔门户登录再跳转至教务系统并进入成绩模块，但是发现怎么都无法成功，于是查询表单发现：
    
    ![随机数](http://img.elfship.cn/img/QQ图片20200315002639.png)
    该处绿色箭头表示有一个随机数 `1t` 以及其他信息，随机数每次提交表单时会变化。其他信息是固定值。

    同时，还发现学号和密码都是明文表示，也没有验证码和其他特殊信息。
    
    所以应对策略是先请求网页将除了学号、密码以外的所有表单信息全部记录下来，接着连同学号和密码一起提交，即可登录。

    成功登录后还是遇到了另外一个问题：即使利用session也无法在翱翔门户跳转到教务系统

- 解决
  
    放弃从翱翔门户进入教务系统，直接找到教务系统的特定登录url: `http://us.nwpu.edu.cn/eams/login.action` 然后继续观察FormData，发现这次登录的表单信息更加简单，省略了随机数，仅有`username`、`password`、`encodedPassword`(这里为空)、`session_locale`（设置中英文的选项，中文用“zh-CN”表示）
    
    然后顺利登录。


    
### 爬取
成绩部分的url非常有规律，可以直接指定参数`semesterId`以访问不同学期的成绩单。

- 问题  
  
    成绩部分的代码虽然并没有用js或其他机制，是可以直接爬取的，但还是遇到了问题——每个学期的成绩表格格式不一样，例如有的学期有实验成绩，而有的学期没有；
    
    并且，同一学期不同人的表格也不一样，有的人有补考成绩，有的人没有。所以不能用简单的索引来读取。
    
    再加上，这些选项之间在属性和标签上没有任何差异，bs无法通过find函数读取特定的某一项以保存。
    ![成绩单格式](http://img.elfship.cn/img/QQ图片20200315004729.png)

- 解决
  
    直接利用pandas的DataFrame数据结构读取会非常方便，可以实现项名和值之间的映射。
    
    首先利用字典将“课程序号”“课程代码”“课程名称”等这些全部读取，接着逐行读取数据（每个‘tr’属性），最后转化为DataFrame格式。这样代码对于任何格式的表格都可以直接读取。

    并且pandas只需调用to_excel函数即可输入到xlsx文件，非常方便。


### 应对反爬虫
实际上并没有发现教务系统的登录和成绩单有明显的反爬虫的机制（登录上没有随机数，复杂程度与翱翔门户比也差了很多，数据也没有被隐藏）；
此外，也没有看到robots协议。

但是为了以防万一，还是写了一个非常简单的应对反爬虫的策略——python的默认User-agent会暴露自己爬虫的身份，所以这里构造UA池，每次随机选用百度、谷歌、safari、Maxthon浏览器中的一个User-agent访问，这样可以认为是一个小网络中多个用户同时访问一个页面，即不会被认为是爬虫。
``` python 
ua_list=[#ua池
    'Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)',
    #百度
    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.94 Safari/537.36',
    #谷歌 
    'User-Agent:Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50', 
    # Safari  
    'Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Maxthon2.0)'
    #（Maxthon）
]
```
## 结果图
1. 输入学号、密码，开始界面：
![结果-界面](http://img.elfship.cn/img/QQ图片20200315010419.png)
2. 选择2017-2018秋学期：
![结果-输出](http://img.elfship.cn/img/QQ图片20200315010739.png)
并选择多个选项查看；   
3. 显示文件已经输出：
![excel文件](http://img.elfship.cn/img/QQ图片20200315010958.png)
4. 在output文件夹中查看其中一个excel文件：
![excel表格细节](http://img.elfship.cn/img/QQ图片20200315011035.png)
